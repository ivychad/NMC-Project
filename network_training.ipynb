{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:33:50.500027534Z",
     "start_time": "2024-12-09T10:33:50.418207358Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import networkx as nx\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.lax import scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN Architecture Null Model - Input & Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates a Networkx Graph that has the structure we want for the SNN. It generates a bunch of randomly connected neurons of which 80% are excitatory and 20% inhibitory. Further the sparsity of the network can be controlled. Additionally, an input layer of n neurons is added which is randomly connected to a subset of the main network with excitatory connections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity test: 3 Neurons in a chain, no learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code simulates only 3 neurons, which are connected in a chain + no self-connections. Only the first neuron in the chain receives external input. The activity looks as expected. Play around with the connectivity matrix and the value of I_ext in the network_update function to see how the network behaves. Notice currently weights do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network of neurons with input and STDP with connectivity generated from networkx graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same code as for the 3 neuron simulation, but now the connectivity matrix is initialized from the networkx graph with input and main neurons. Initial weights are true to Dale's principle, but it needs to be fixed that neurons do not switch from excitatory to inhibtiory over time with STDP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Network Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a slightly improved version of the graph above which ensures that all neurons have outgoing connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:33:53.602658864Z",
     "start_time": "2024-12-09T10:33:50.484057164Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_neural_network(num_neurons, excitatory_ratio=0.8, connection_prob=0.1):\n",
    "    \"\"\"\n",
    "    Generates a neural network with excitatory and inhibitory neurons.\n",
    "\n",
    "    Args:\n",
    "        num_neurons (int): Total number of neurons.\n",
    "        excitatory_ratio (float): Proportion of excitatory neurons (default: 0.8, for 4:1 ratio).\n",
    "        connection_prob (float): Probability of connection between any two neurons.\n",
    "    \n",
    "    Returns:\n",
    "        G (nx.DiGraph): Directed graph representing the network.\n",
    "    \"\"\"\n",
    "    # Number of excitatory and inhibitory neurons\n",
    "    num_excitatory = int(num_neurons * excitatory_ratio)\n",
    "    num_inhibitory = num_neurons - num_excitatory\n",
    "\n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes with attributes (excitatory or inhibitory)\n",
    "    for i in range(num_neurons):\n",
    "        if i < num_excitatory:\n",
    "            G.add_node(i, type=1)\n",
    "        else:\n",
    "            G.add_node(i, type=-1)\n",
    "\n",
    "    # Add edges with weights, respecting Dale's principle\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(num_neurons):\n",
    "            if i != j and np.random.rand() < connection_prob:\n",
    "                if G.nodes[i][\"type\"] == 1:\n",
    "                    weight = np.random.normal(5.0, 1.0)  # Positive weight for excitatory\n",
    "                else:\n",
    "                    weight = np.random.normal(-5.0, 1.0)  # Negative weight for inhibitory\n",
    "                G.add_edge(i, j, weight=weight)\n",
    "    \n",
    "    # Ensure each excitatory or inhibitory neuron has at least one outgoing connection\n",
    "    for i in range(num_neurons):\n",
    "        if len(list(G.out_edges(i))) == 0:  # No outgoing connections\n",
    "            # Find a random target neuron\n",
    "            target = np.random.choice(num_neurons)\n",
    "            while target == i:  # Ensure no self-loop\n",
    "                target = np.random.choice(num_neurons)\n",
    "            if G.nodes[i][\"type\"] == 1:\n",
    "                weight = np.random.normal(5.0, 1.0)  # Positive weight for excitatory\n",
    "            else:\n",
    "                weight = np.random.normal(-5.0, 1.0)  # Negative weight for inhibitory\n",
    "            G.add_edge(i, target, weight=weight)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def add_input_layer(G, num_input_nodes=10, subset_size=30, input_prob=0.5):\n",
    "    \"\"\"\n",
    "    Adds an input layer to the neural network.\n",
    "\n",
    "    Args:\n",
    "        G (nx.DiGraph): Existing neural network graph.\n",
    "        num_input_nodes (int): Number of input nodes to add.\n",
    "        subset_size (int): Size of the subset of existing neurons to connect to.\n",
    "        input_prob (float): Probability of connection from input nodes to subset neurons.\n",
    "\n",
    "    Returns:\n",
    "        G (nx.DiGraph): Updated graph with input layer.\n",
    "    \"\"\"\n",
    "    num_existing_neurons = len(G.nodes)\n",
    "    input_layer_start = num_existing_neurons\n",
    "\n",
    "    # Add input nodes\n",
    "    for i in range(num_input_nodes):\n",
    "        G.add_node(input_layer_start + i, type=0)\n",
    "\n",
    "    # Randomly select a subset of existing neurons\n",
    "    subset_neurons = np.random.choice(num_existing_neurons, subset_size, replace=False)\n",
    "\n",
    "    # Add edges from input nodes to subset neurons with the given probability\n",
    "    for input_node in range(input_layer_start, input_layer_start + num_input_nodes):\n",
    "        for target_neuron in subset_neurons:\n",
    "            if np.random.rand() < input_prob:\n",
    "                weight = np.random.uniform(5, 10)  # Adjust weight range if needed\n",
    "                G.add_edge(input_node, target_neuron, weight=weight)\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "def plot_network(G):\n",
    "    \"\"\"\n",
    "    Plots the network, color-coding excitatory and inhibitory neurons.\n",
    "\n",
    "    Args:\n",
    "        G (nx.DiGraph): Directed graph representing the network.\n",
    "    \"\"\"\n",
    "    pos = nx.random_layout(G)  # Layout for visualization\n",
    "    excitatory_nodes = [n for n, attr in G.nodes(data=True) if attr[\"type\"] == 1]\n",
    "    inhibitory_nodes = [n for n, attr in G.nodes(data=True) if attr[\"type\"] == -1]\n",
    "    input_nodes = [n for n, attr in G.nodes(data=True) if attr[\"type\"] == 0]\n",
    "    \n",
    "    num_input_nodes = len(input_nodes)\n",
    "    for i, node in enumerate(input_nodes):\n",
    "        pos[node] = (-0.1, i / (num_input_nodes - 1) if num_input_nodes > 1 else 0.5)\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=excitatory_nodes, node_color=\"red\", label=\"Excitatory\", alpha=0.7, node_size=50)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=inhibitory_nodes, node_color=\"blue\", label=\"Inhibitory\", alpha=0.7, node_size=50)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=input_nodes, node_color=\"green\", label=\"Input Nodes\", alpha=0.7, node_size=50)\n",
    "\n",
    "    # Draw edges\n",
    "    weights = nx.get_edge_attributes(G, \"weight\")\n",
    "    excitatory_edges = [(u, v) for u, v, d in G.edges(data=True) if G.nodes[u][\"type\"] == 1]\n",
    "    inhibitory_edges = [(u, v) for u, v, d in G.edges(data=True) if G.nodes[u][\"type\"] == -1]\n",
    "    input_edges = [(u, v) for u, v, d in G.edges(data=True) if G.nodes[u][\"type\"] == 0]\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=excitatory_edges, edge_color=\"red\", arrowstyle=\"->\", arrowsize=10, alpha=0.7, label=\"Excitatory Connections\")\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=inhibitory_edges, edge_color=\"blue\", arrowstyle=\"->\", arrowsize=10, alpha=0.7, label=\"Inhibitory Connections\")\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=input_edges, edge_color=\"green\", arrowstyle=\"->\", arrowsize=10, alpha=0.7, label=\"Input Connections\")\n",
    "\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "    plt.title(\"Neural Network with Excitatory and Inhibitory Neurons\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Parameters\n",
    "num_neurons = 1000  # Total number of neurons\n",
    "excitatory_ratio = 0.8  # 4:1 ratio (80% excitatory)\n",
    "connection_prob = 0.1  # Connection probability\n",
    "\n",
    "# Generate and plot network\n",
    "G = generate_neural_network(num_neurons, excitatory_ratio, connection_prob)\n",
    "G = add_input_layer(G, num_input_nodes=784, subset_size=400, input_prob=0.5)\n",
    "# plot_network(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simulation with 100 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:37:08.023170356Z",
     "start_time": "2024-12-09T10:37:06.860996913Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 14:05:08.987935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733749508.998647   37327 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733749509.001607   37327 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-09 14:05:10.426282: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/eelke/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a5fefe119442b597142a3424fbbc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /home/eelke/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733749515.872679   37327 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Define transformations (convert to tensor, normalize)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=False, transform=transform)\n",
    "\n",
    "# Convert data to NumPy arrays\n",
    "train_images = np.array([np.array(img[0]).squeeze() for img in train_dataset])\n",
    "train_labels = np.array([label for _, label in train_dataset])\n",
    "\n",
    "test_images = np.array([np.array(img[0]).squeeze() for img in test_dataset])\n",
    "test_labels = np.array([label for _, label in test_dataset])\n",
    "\n",
    "# Convert to JAX arrays\n",
    "train_images = jnp.array(train_images, dtype=jnp.float32)\n",
    "train_labels = jnp.array(train_labels, dtype=jnp.int32)\n",
    "\n",
    "test_images = jnp.array(test_images, dtype=jnp.float32)\n",
    "test_labels = jnp.array(test_labels, dtype=jnp.int32)\n",
    "\n",
    "train_images = train_images * 255.0\n",
    "test_images = test_images *255.0\n",
    "\n",
    "# Normalize images\n",
    "#train_images /= 255.0\n",
    "#test_images /= 255.0\n",
    "\n",
    "# Outputs: train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:37:08.023170356Z",
     "start_time": "2024-12-09T10:37:06.860996913Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the MNIST dataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ds_builder \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mbuilder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the MNIST dataset\n",
    "ds_builder = tfds.builder('mnist')\n",
    "ds_builder.download_and_prepare()\n",
    "train_ds = tfds.as_numpy(\n",
    "    ds_builder.as_dataset(split=\"train\", batch_size=-1))\n",
    "test_ds = tfds.as_numpy(ds_builder.as_dataset(split=\"test\", batch_size=-1))\n",
    "\n",
    "# Normalize data\n",
    "train_images, train_labels = train_ds['image'], train_ds['label']\n",
    "test_images, test_labels = test_ds['image'], test_ds['label']\n",
    "\n",
    "train_images = jnp.float32(train_images)*255.0\n",
    "# train_images = jnp.float32(train_images) / 255.0\n",
    "test_images = jnp.float32(test_images)*255.0\n",
    "# test_images = jnp.float32(test_images) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the 10 input neurons receive external stimulation. This can also be extended to 10x as many or more neurons and works too, but some things need to be changed in the code itself too (which subset receives input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:37:25.328850235Z",
     "start_time": "2024-12-09T10:37:22.329461434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# AdEx neuron dynamics\n",
    "def adex_dynamics(state, neuron_params, inputs):\n",
    "    \"\"\"AdEx neuron dynamics with spiking and refractory period.\"\"\"\n",
    "    v, w, refractory_timer = state\n",
    "    I_ext, I_syn = inputs\n",
    "\n",
    "    refractory_logic = lambda _: (\n",
    "        neuron_params[\"v_reset\"], w, refractory_timer - 1, 0.0\n",
    "    )\n",
    "\n",
    "    normal_logic = lambda _: (\n",
    "        v + (-(v - neuron_params[\"v_rest\"])\n",
    "             + neuron_params[\"delta_T\"] * jnp.exp((v - neuron_params[\"v_th\"]) / neuron_params[\"delta_T\"])\n",
    "             - w + I_ext + I_syn) / neuron_params[\"tau_v\"],\n",
    "        w + (neuron_params[\"a\"] * (v - neuron_params[\"v_rest\"]) - w +\n",
    "             neuron_params[\"b\"] * (v > neuron_params[\"v_th\"])) / neuron_params[\"tau_w\"],\n",
    "        jnp.where(v > neuron_params[\"v_th\"], neuron_params[\"refractory\"], 0.0),\n",
    "        (v > neuron_params[\"v_th\"]).astype(float)\n",
    "    )\n",
    "\n",
    "    v_new, w_new, refractory_timer_new, spiked = jax.lax.cond(\n",
    "        refractory_timer > 0, refractory_logic, normal_logic, operand=None\n",
    "    )\n",
    "    \n",
    "    v_new = jnp.minimum(v_new, 40.0)\n",
    "    v_new = jnp.maximum(v_new,-100.0)\n",
    "\n",
    "    return jnp.array([v_new, w_new, refractory_timer_new]), spiked\n",
    "\n",
    "# Exponential synapse dynamics\n",
    "def synaptic_dynamics(syn_state, syn_params, pre_spike):\n",
    "    \"\"\"Exponential synaptic dynamics.\"\"\"\n",
    "    return syn_state + (-syn_state / syn_params[\"tau_syn\"] + pre_spike)\n",
    "\n",
    "# STDP weight updates\n",
    "def update_weights(weights, pre_spikes, post_spikes, stdp_params, connectivity):\n",
    "    \"\"\"Update synaptic weights using the STDP rule with exponential time dependence.\"\"\"\n",
    "    \n",
    "    # Compute the time differences (t = t_post - t_pre) for each pair of neurons\n",
    "    delta_t = post_spikes[:, None] - pre_spikes[None, :]\n",
    "    \n",
    "    # Calculate the weight updates for LTP (pre before post) and LTD (post before pre)\n",
    "    delta_w_plus = stdp_params[\"A_plus\"] * jnp.exp(-delta_t / stdp_params[\"tau_plus\"]) * (delta_t > 0)  # t > 0: LTP\n",
    "    delta_w_minus = stdp_params[\"A_minus\"] * jnp.exp(delta_t / stdp_params[\"tau_minus\"]) * (delta_t < 0)  # t < 0: LTD\n",
    "    \n",
    "    # Calculate the total weight change\n",
    "    weight_updates = delta_w_plus - delta_w_minus\n",
    "\n",
    "    # add here that weights cannot change direction - Dale's principle\n",
    "\n",
    "    # Ensure that weights initialized to zero stay at zero (for the synapses with no connectivity)\n",
    "    weights = jnp.where(connectivity == 0, weights, weights + weight_updates)\n",
    "    \n",
    "    # Clip the weights to keep them within a defined range, avoiding runaway values\n",
    "    return jnp.clip(weights, -20.0, 20.0)\n",
    "\n",
    "\n",
    "# Network update function\n",
    "def network_update(carry, t, params, I_ext):\n",
    "    neuron_states, synapse_states, weights, key = carry\n",
    "    key, subkey = random.split(key)\n",
    "\n",
    "\n",
    "\n",
    "    pre_spikes = (neuron_states[:, 0] > params[\"neuron\"][\"v_th\"]).astype(float)\n",
    "\n",
    "    # Synaptic dynamics: update synapse states\n",
    "    synapse_states = jax.vmap(synaptic_dynamics, in_axes=(0, None, 0))(\n",
    "        synapse_states, params[\"synapse\"], pre_spikes\n",
    "    )\n",
    "    I_syn = jnp.dot(weights, synapse_states)\n",
    "\n",
    "    # Neuron dynamics: update states\n",
    "    neuron_states, spiked = jax.vmap(adex_dynamics, in_axes=(0, None, 0))(\n",
    "        neuron_states, params[\"neuron\"], jnp.stack([I_ext, I_syn], axis=-1)\n",
    "    )\n",
    "\n",
    "    # Update weights\n",
    "    # Update weights with STDP\n",
    "    weights = update_weights(weights, pre_spikes, spiked, params[\"stdp\"], connectivity)\n",
    "\n",
    "    return (neuron_states, synapse_states, weights, key), (neuron_states[:, 0], spiked)\n",
    "\n",
    "# Simulation\n",
    "def simulate(T, dt, N, key, params, connectivity, train_images):\n",
    "    neuron_states = jnp.stack([\n",
    "        jnp.full((N,), params[\"neuron\"][\"v_rest\"]),\n",
    "        jnp.zeros(N),\n",
    "        jnp.zeros(N)\n",
    "    ], axis=-1)\n",
    "    synapse_states = jnp.zeros(N)\n",
    "    weights = jnp.array(connectivity)\n",
    "    carry = (neuron_states, synapse_states, weights, key)\n",
    "    time_steps = jnp.arange(0, T, dt)\n",
    "    \n",
    "    \n",
    "    # External input: stimulate neuron 0 for demonstration\n",
    "    \n",
    "    img = train_images[0].flatten()\n",
    "    \n",
    "    mean_input = 8.0\n",
    "    std_input = jnp.sqrt(2.0)  # Standard deviation is sqrt(variance)\n",
    "    r = jax.random.normal(key, (784,)) * std_input + mean_input\n",
    "\n",
    "    # Create random input for the last 10 neurons\n",
    "    I_ext = jnp.zeros(len(neuron_states))\n",
    "    I_ext = I_ext.at[1000:].set(img)\n",
    "    \n",
    "    carry, outputs = scan(lambda carry, t: network_update(carry, t, params, I_ext), carry, time_steps)\n",
    "    membrane_potentials, spikes = outputs\n",
    "    weights = carry[2]\n",
    "    return jnp.array(membrane_potentials).T, jnp.array(spikes).T, jnp.array(weights).T, time_steps\n",
    "    # return jnp.array(membrane_potentials).T, jnp.array(spikes).T, jnp.array(weights).T, time_steps\n",
    "\n",
    "# Plotting results\n",
    "def plot_results(time, membrane_potentials, spikes, weights):\n",
    "\n",
    "    norm = TwoSlopeNorm(vmin=-5, vcenter=0, vmax=5)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.plot(time, membrane_potentials.T[:, :])\n",
    "    plt.title(\"Membrane Potentials\")\n",
    "    plt.xlabel(\"Time (ms)\")\n",
    "    plt.ylabel(\"Potential (mV)\")\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.imshow(spikes, aspect=\"auto\", cmap=\"gray_r\", origin=\"lower\")\n",
    "    plt.title(\"Spike Raster Plot\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Neuron Index\")\n",
    "\n",
    "    plt.subplot(5, 1, 3)\n",
    "    plt.imshow(connectivity, aspect=\"auto\", cmap=\"seismic\", origin=\"lower\", norm=norm)\n",
    "    plt.title(\"Synaptic Weights Beginning\")\n",
    "    plt.xlabel(\"Neuron Index\")\n",
    "    plt.ylabel(\"Neuron Index\")\n",
    "    plt.colorbar(label=\"Weight\")\n",
    "    \n",
    "    plt.subplot(5, 1, 4)\n",
    "    plt.imshow(weights[:,:].T, aspect=\"auto\", cmap=\"seismic\", origin=\"lower\", norm=norm)\n",
    "    plt.title(\"Synaptic Weights End\")\n",
    "    plt.xlabel(\"Neuron Index\")\n",
    "    plt.ylabel(\"Neuron Index\")\n",
    "    plt.colorbar(label=\"Weight\")\n",
    "    \n",
    "    plt.subplot(5, 1, 5)\n",
    "    plt.imshow(weights[:,:], aspect=\"auto\", cmap=\"seismic\", origin=\"lower\", norm=norm)\n",
    "    plt.title(\"Synaptic Weights End\")\n",
    "    plt.xlabel(\"Neuron Index\")\n",
    "    plt.ylabel(\"Neuron Index\")\n",
    "    plt.colorbar(label=\"Weight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(9,7))\n",
    "    plt.imshow(weights[:,:], aspect=\"auto\", cmap=\"seismic\", origin=\"lower\", norm=norm)\n",
    "    plt.title(\"Synaptic Weights End\")\n",
    "    plt.xlabel(\"Neuron Index\")\n",
    "    plt.ylabel(\"Neuron Index\")\n",
    "    plt.colorbar(label=\"Weight\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# Define the connectivity matrix\n",
    "N = 1784\n",
    "\n",
    "# convert graph to connectivity matrix\n",
    "adj_matrix_sparse = nx.adjacency_matrix(G)\n",
    "adj_matrix_dense = adj_matrix_sparse.toarray()\n",
    "connectivity = jnp.array(adj_matrix_dense).T\n",
    "\n",
    "# Simulation parameters\n",
    "key = random.PRNGKey(42)\n",
    "T = 200  # Simulation time (ms)\n",
    "dt = 1.0  # Time step (ms)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    \"neuron\": {\n",
    "        \"v_rest\": -65.0,  # Resting membrane potential (mV)\n",
    "        \"v_th\": -50.0,    # Threshold potential (mV)\n",
    "        \"delta_T\": 2.0,   # Slope factor (mV)\n",
    "        \"tau_v\": 20.0,    # Membrane time constant (ms)\n",
    "        \"a\": 0.5,        # Subthreshold adaptation (nS)\n",
    "        \"b\": 7,         # Spike-triggered adaptation (nA)\n",
    "        \"tau_w\": 100.0,   # Adaptation time constant (ms)\n",
    "        \"v_reset\": -70.0, # Reset potential after spike (mV)\n",
    "        \"refractory\": 2.0 # Refractory period (ms)\n",
    "    },\n",
    "    \"synapse\": {\n",
    "        \"tau_syn\": 10.0  # Synaptic time constant (ms)\n",
    "    },\n",
    "    \"stdp\": {\n",
    "        \"A_plus\": 1,   # STDP LTP increment\n",
    "        \"A_minus\": 0.5, # STDP LTD decrement\n",
    "        \"tau_plus\": 10.0, # STDP LTP time constant (ms)\n",
    "        \"tau_minus\": 5.0 # STDP LTD time constant (ms)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Run the simulation\n",
    "membrane_potentials, spikes, weights, time = simulate(T, dt, N, key, params, connectivity, train_images)\n",
    "plot_results(time, membrane_potentials, spikes, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T10:33:58.476200140Z",
     "start_time": "2024-12-09T10:33:58.391042967Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
